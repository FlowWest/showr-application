mutate(classification = wy_class_lookups[yr_type]) %>%
pull(classification) %>%
as.character()
} else {
current_water_year_types %>%
filter(probability == 99) %>%
arrange(desc(date)) %>%
head(1) %>%
pull(classification) %>%
as.character()
}
}
# run this to make the .Rdata object file
save(
redd_cdec_lookup,
station_code_to_name_flows,
station_code_to_name_temps,
redd_reach_center_coords,
redd_locations,
wy_class_lookups,
get_year_classification,
file = "data/general-objects.RData"
)
library(shiny)
library(plotly)
library(dplyr)
library(lubridate)
library(DT)
library(leaflet)
library(rgdal)
library(zoo)
library(stringr)
library(readr)
library(tidyr)
library(forcats)
library(readr)
library(sparkline)
library(shinyjs)
library(measurements)
library(purrr)
# atu
source("atu.R")
# modules -----------------------------------------------------------------------
source("modules/dashboard-page.R")
source("modules/temperature-page.R")
source("modules/winter-run-chinook-page.R")
source("modules/flow-page.R")
source("modules/about-page.R")
source("modules/welcome.R")
# load general objects, documented in "data/make-general-objects.R"
load("data/general-objects.RData")
diversion_data <- read_csv("data/flows/srsc_diversion_data.csv") %>%
mutate(draft_date = mdy(draft_date))
Red Bluff Diversion Dam to Tehama Bridge
# These data are all on a public S3 bucket
temp_data <-
read_csv("https://s3-us-west-2.amazonaws.com/showr-data-site/showr_hourly_temps.csv",
col_types = cols(
datetime = col_datetime(format = ""),
location_id = col_character(),
parameter_id = col_integer(),
parameter_value = col_double()
))
temp_compliance_points_daily_mean <-
read_csv("https://s3-us-west-2.amazonaws.com/showr-data-site/showr_tempatures.csv",
col_types = cols(
datetime = col_date(format = ""),
location_id = col_character(),
parameter_id = col_integer(),
parameter_value = col_double()
))
flow_data <-
read_csv("https://s3-us-west-2.amazonaws.com/showr-data-site/showr_hourly_flows.csv",
col_types = cols(
location_id = col_character(),
parameter_id = col_integer(),
datetime = col_datetime(format = ""),
parameter_value = col_integer()
))
flow_data_daily_mean <-
read_csv("https://s3-us-west-2.amazonaws.com/showr-data-site/showr_flow.csv",
col_types = cols(
datetime = col_date(format = ""),
location_id = col_character(),
parameter_id = col_integer(),
parameter_value = col_double()
))
shasta_storage_data <-
read_csv("https://s3-us-west-2.amazonaws.com/showr-data-site/showr_ops.csv",
col_types = cols(
datetime = col_date(format = ""),
location_id = col_character(),
parameter_id = col_integer(),
parameter_value = col_double()
))
redd_data <-
read_csv("https://s3-us-west-2.amazonaws.com/showr-data/cdfw/redds/aerial-survey-observations_no_error_codes.csv",
col_types = cols(
date = col_date(format = ""),
location = col_character(),
race = col_character(),
counts = col_double()
)) %>% filter(race == "Winter")
carcass_data <- read_rds("data/chinook/carcass_static_data.rds")
# shape files for redd map
redd_reach <- readOGR("data/redd_reaches/redd_reach.shp", stringsAsFactors = FALSE)
redd_reach <- spTransform(redd_reach, CRS("+proj=longlat +datum=WGS84 +no_defs"))
carcass_reach <- readOGR("data/carcass_reaches/carcass_reach_line.shp")
carcass_reach <- spTransform(carcass_reach, CRS("+proj=longlat +datum=WGS84 +no_defs"))
carcass_location <- carcass_reach$Reach
# TODO: this is ok for now but needs to be modified, by either having the data
# come into the shiny app with the sections names already in the dataset
carcass_section_to_reach_name <- data.frame(
river_section = as.character(1:4),
section_name = carcass_reach$Reach,
stringsAsFactors = FALSE
)
carcass_data <-
left_join(carcass_data, carcass_section_to_reach_name, c("river_section" = "river_section"))
# TCD Configurations
tcd_configs_data <- read_rds("data/tcd_configurations/tcd_configs_through_2017-08-24.rds")
# temp locations metadata
cdec_temperature_locations <- read_rds("data/temperatures/cdec_temperature_locations.rds")
model_temps <- read_csv("https://s3-us-west-2.amazonaws.com/svproducers-data/cvtemp_data/2017-08-25_10%3A00%3A15_model_output.csv")
model_temps$datetime <- as_date(model_temps$datetime)
# winter run presence
wr_presence_data <- read_csv("data/chinook/wr_chinook_presence.csv")
# water year index classifications
historic_water_year_types <-
readr::read_rds("data/operations/historical-water-year-index.rds") %>%
tibble::add_row(year =2017, yr_type="W")
current_water_year_types <-
readr::read_rds("data/operations/2018-04-17-water-year-index.rds")
pretty_num <- function(num, places = 2) {
format(round(num, places), big.mark = ',', drop = FALSE)
}
isothermal_data <- read_rds("data/operations/shasta_storage_temperature.rds")
get_year_classification <- function(y) {
if (y != year(today())) {
historic_water_year_types %>%
filter(year == y) %>%
mutate(classification = wy_class_lookups[yr_type]) %>%
pull(classification) %>%
as.character()
} else {
current_water_year_types %>%
filter(probability == 99) %>%
arrange(desc(date)) %>%
head(1) %>%
pull(classification) %>%
as.character()
}
}
# for winter run emergence
daily_temps <- temp_data %>%
group_by(cdec_gage = location_id, date = as_date(datetime)) %>%
summarise(
daily_mean = mean(parameter_value, na.rm = TRUE)
) %>% ungroup()
### NO TEMPERATURE DATA BEFORE 2010!!!!
rd <- redd_data %>%
filter(counts > 0, year(date) >= 2010) %>%
rowwise() %>%
do(
tibble(
date = seq(.$date, estimate_emergence(.$date, .$location) -1, by="day"),
location = .$location,
counts = .$counts
)
) %>% ungroup() %>%
mutate(cdec_gage = redd_cdec_lookup[location],
location = factor(location, levels = unique(redd_data$location))) %>%
left_join(daily_temps)
redd_data %>%
filter(year(date) == 2017) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps) %>%
filter(is.na(daily_mean))
redd_data %>%
filter(year(date) == 2017) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps)
redd_data %>%
filter(year(date) == 2017) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps) %>%
mutate(temp_exceed = daily_mean > 56) %>%
group_by(temp_exceed) %>%
summarise(count = n())
redd_data %>%
filter(year(date) == 2017) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps) %>%
mutate(temp_exceed = daily_mean > 56) %>%
group_by(temp_exceed) %>%
summarise(sum(temp_exceed) /count = n())
redd_data %>%
filter(year(date) == 2017) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps) %>%
mutate(temp_exceed = daily_mean > 56) %>%
group_by(temp_exceed) %>%
summarise(sum(temp_exceed) /n())
redd_data %>%
filter(year(date) == 2017) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps) %>%
mutate(temp_exceed = daily_mean > 56) %>%
group_by(temp_exceed) %>%
summarise(sum(temp_exceed)/n() * 100)
redd_data %>%
filter(year(date) == 2017) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps) %>%
mutate(temp_exceed = daily_mean > 56) %>%
group_by(temp_exceed) %>%
summarise(n())
redd_data %>%
filter(year(date) == 2017) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps) %>%
mutate(temp_exceed = daily_mean > 56) %>%
summarise(n())
redd_data %>%
filter(year(date) == 2017) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps) %>%
mutate(temp_exceed = daily_mean > 56) %>%
summarise(total = n(), temp_danger = sum(temp_exceed))
runApp()
runApp()
redd_data
runApp()
output$wr_table <- renderTable(
redd_data %>%
filter(year(date) == 2017) %>% #input$wr_select_year) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps) %>%
mutate(temp_exceed = daily_mean > 56 * counts) %>%
summarise(`Total` = n(), `Temperature Threatened` = sum(temp_exceed)))
output$wr_table <- renderTable(
redd_data %>%
filter(year(date) == 2017) %>% #input$wr_select_year) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps) %>%
mutate(temp_exceed = daily_mean > 56 * counts) %>%
summarise(`Total` = n(), `Temperature Threatened` = sum(temp_exceed)))
redd_data %>%
filter(year(date) == 2017) %>% #input$wr_select_year) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps) %>%
mutate(temp_exceed = daily_mean > 56 * counts) %>%
summarise(`Total` = n(), `Temperature Threatened` = sum(temp_exceed))
redd_data %>%
filter(year(date) == 2017) %>% #input$wr_select_year) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps) %>%
mutate(temp_exceed = daily_mean > 56) %>% View
redd_data %>%
filter(year(date) == 2017) %>% #input$wr_select_year) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps) %>%
mutate(temp_exceed = daily_mean > 56 * counts) %>% View
output$wr_table <- renderTable(
redd_data %>%
filter(year(date) == 2017, counts > 0) %>% #input$wr_select_year) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps) %>%
mutate(temp_exceed = daily_mean > 56) %>%
summarise(`Total` = n(), `Temperature Threatened` = sum(temp_exceed)))
redd_data %>%
filter(year(date) == 2017) %>% #input$wr_select_year) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps) %>%
mutate(temp_exceed = daily_mean > 56) %>% View
redd_data %>%
filter(year(date) == 2017, counts > 0) %>% #input$wr_select_year) %>%
mutate(cdec_gage = redd_cdec_lookup[location]) %>%
left_join(daily_temps) %>%
mutate(temp_exceed = daily_mean > 56) %>% View
rd
rd %>%
mutate(temp_exceed = daily_mean > 56) %>%
summarise(`Total` = n(), `Temperature Threatened` = sum(temp_exceed)))
rd %>%
mutate(temp_exceed = daily_mean > 56) %>%
summarise(`Total` = n(), `Temperature Threatened` = sum(temp_exceed))
rd %>%
mutate(temp_exceed = daily_mean > 56)
?group_indices
### NO TEMPERATURE DATA BEFORE 2010!!!!
rd <- redd_data %>%
filter(counts > 0, year(date) >= 2010) %>%
mutate(redd_id = row_number(date)) %>%
rowwise() %>%
do(
tibble(
date = seq(.$date, estimate_emergence(.$date, .$location) -1, by="day"),
location = .$location,
counts = .$counts,
redd_id = redd_id
)
) %>% ungroup() %>%
mutate(cdec_gage = redd_cdec_lookup[location],
location = factor(location, levels = unique(redd_data$location))) %>%
left_join(daily_temps)
### NO TEMPERATURE DATA BEFORE 2010!!!!
rd <- redd_data %>%
filter(counts > 0, year(date) >= 2010) %>%
mutate(redd_id = row_number(date)) %>%
rowwise() %>%
do(
tibble(
date = seq(.$date, estimate_emergence(.$date, .$location) -1, by="day"),
location = .$location,
counts = .$counts,
redd_id = .$redd_id
)
) %>% ungroup() %>%
mutate(cdec_gage = redd_cdec_lookup[location],
location = factor(location, levels = unique(redd_data$location))) %>%
left_join(daily_temps)
rd
tail()
tail(rd)
dim(redd_data)
dim(filter(redd_data, year(date) >= 2010)
)
933 / 139
dim(filter(redd_data, year(date) >= 2010, counts > 0))
rd %>%
group_by(redd_id) %>%
mutate(temp_exceed = daily_mean > 56) %>%
summarise(`Total` = n(), `Temperature Threatened` = sum(temp_exceed))
rd %>%
group_by(redd_id) %>%
mutate(temp_exceed = daily_mean > 56)
rd %>%
filter(year(date) == 2017) %>%
group_by(redd_id) %>%
mutate(temp_exceed = daily_mean > 56) %>%
summarise(`Total` = n(), `Temperature Threatened` = sum(temp_exceed))
rd %>%
filter(year(date) == 2017) %>%
group_by(redd_id) %>%
summarise(temp_exceed = daily_mean > 56)
rd %>%
filter(year(date) == 2017) %>%
group_by(redd_id) %>%
mutate(temp_exceed = daily_mean > 56) %>%
summarise(`Total` = n(), `Temperature Threatened` = sum(temp_exceed))
rd %>%
filter(year(date) == 2017) %>%
group_by(redd_id) %>%
mutate(temp_exceed = daily_mean > 56) %>%
summarise(`Total` = n(), `Temperature Threatened` = sum(temp_exceed)) %>%
ungroup() %>%
summarise(`Total` = n(), `Temperature Threatened` = `Temperature Threatened`)
rd %>%
filter(year(date) == 2017) %>%
group_by(redd_id) %>%
mutate(temp_exceed = daily_mean > 56) %>%
summarise(`Total` = n(), `Temperature Threatened` = sum(temp_exceed)) %>%
ungroup() %>%
summarise(`Total` = n(), `Temperature Threatened` = sum(`Temperature Threatened`))
runApp()
runApp()
rd %>%
filter(year(date) == 2017) %>%
group_by(redd_id) %>%
mutate(temp_exceed = daily_mean > 56) %>%
summarise(`Total` = n(), `Temperature Threatened` = sum(temp_exceed)) %>%
ungroup() %>%
summarise(`Total` = n(), `Temperature Threatened` = sum(`Temperature Threatened`))
rd %>%
filter(year(date) == 2014) %>%
group_by(redd_id) %>%
mutate(temp_exceed = daily_mean > 56) %>%
summarise(`Total` = n(), `Temperature Threatened` = sum(temp_exceed)) %>%
ungroup() %>%
summarise(`Total` = n(), `Temperature Threatened` = sum(`Temperature Threatened`))
rd %>%
filter(year(date) == 2014) %>%
group_by(redd_id) %>%
mutate(temp_exceed = daily_mean > 56) %>%
summarise(`Total` = sum(counts), `Temperature Threatened` = sum(temp_exceed))
View(redd_data)
View(filter(year(date)==2014, redd_data))
View(filter(redd_data, year(date)==2014))
View(filter(redd_data, year(date)==2014, counts > 0))
rd %>%
filter(year(date) == 2014, counts > 0)
rd %>%
filter(year(date) == 2014, counts > 0) %>%
mutate(temp_exceed = daily_mean > 56)
rd %>%
filter(year(date) == 2014, counts > 0) %>%
mutate(temp_exceed = daily_mean > 56) %>%
group_by(redd_id) %>%
summarise(`Total` = counts, `Temperature Threatened` = temp_exceed * counts)
rd %>%
filter(year(date) == 2014, counts > 0) %>%
mutate(temp_exceed = daily_mean > 56) %>%
group_by(redd_id) %>%
summarise(`Total` = max(counts), `Temperature Threatened` = temp_exceed * max(counts))
rd %>%
filter(year(date) == 2014, counts > 0) %>%
mutate(temp_exceed = daily_mean > 56) %>%
group_by(redd_id) %>%
summarise(`Total` = max(counts), `Temperature Threatened` = max(temp_exceed) * max(counts)) #%>%
rd %>%
filter(year(date) == 2014, counts > 0) %>%
mutate(temp_exceed = daily_mean > 56) %>%
group_by(redd_id) %>%
summarise(Total = max(counts), `Temperature Threatened` = max(temp_exceed) * max(counts)) %>%
ungroup() %>%
summarise(Total = sum(Total), `Temperature Threatened` = sum(`Temperature Threatened`))
rd %>%
filter(year(date) == 2017, counts > 0) %>%
mutate(temp_exceed = daily_mean > 56) %>%
group_by(redd_id) %>%
summarise(Total = max(counts), `Temperature Threatened` = max(temp_exceed) * max(counts)) %>%
ungroup() %>%
summarise(Total = sum(Total), `Temperature Threatened` = sum(`Temperature Threatened`))
runApp()
runApp()
runApp()
?round
round(23.4)
as.integer(23.4)
runApp()
runApp()
runApp()
library(shiny)
selectInput("thisID", "thisLabel", choices=2010:2017)
runApp()
runApp()
shiny::runApp()
getwd()
runApp()
runApp()
runApp()
1260/2
runApp()
?purrr::rerun
rerun(10, rnorm(1))
rerun
15000/12
rerun(10, rnorm(1), rnorm(5))
rerun(10, rnorm(1), rnorm(5), 1)
rerun(10, rnorm(1), rnorm(5), 1, 2)
5.5 * 4
22 + 13
8 * 4
5.8 * 26
150.8/8
5 * 26
130/26
130/8
library(shiny)
library(plotly)
library(dplyr)
library(lubridate)
library(DT)
library(leaflet)
library(rgdal)
library(zoo)
library(stringr)
library(readr)
library(tidyr)
library(forcats)
library(readr)
library(sparkline)
library(shinyjs)
library(measurements)
library(purrr)
1816-100
1816-100-1500
runApp()
1816+468
runApp()
historic_water_year_types
historic_water_year_types %>% tail()
get_year_classification()
get_year_classification(2017)
get_year_classification(2015)
runApp()
redd_data
redd_data %>% filter(year(date) == 2017)
redd_data %>% filter(year(date) == 2017) %>% pull(counts)
redd_data %>% filter(year(date) == 2017) %>% pull(counts) %>% sum()
isothermal_data
isothermal_data %>% filter(month(date) == 9)
isothermal_data %>% filter(month(date) == 9, year(date) == 2017)
isothermal_data %>% filter(month(date) == 9, year(date) == 2017) %>% group_by(date) %>% summarise(total = sum(volume_taf))
shasta_storage_data
shasta_storage_data %>% filter(parameter_id == 15)
shasta_storage_data %>% filter(parameter_id == 15, month(date) == 9, year(date) == 2017)
shasta_storage_data %>% filter(parameter_id == 15, month(datetime) == 9, year(datetime) == 2017)
shasta_storage_data %>% filter(parameter_id == 15, month(datetime) == 9, year(datetime) == 2017) %>% arrange(datetime) %>% tail()1
shasta_storage_data %>% filter(parameter_id == 15, month(datetime) == 9, year(datetime) == 2017) %>% arrange(datetime) %>% tail(1)
CDECRetrieve::cdec_datasets("sha")
shasta_storage_data
shasta_storage_data %>% filter(parameter_id == 15)
shasta_storage_data %>% filter(parameter_id == 15, year(datetime) == 2017, month(datetime) == 9)
shasta_storage_data %>% filter(parameter_id == 15, year(datetime) == 2017, month(datetime) == 9) %>% arrange(desc(datetime))
shasta_storage_data %>% filter(parameter_id == 15, year(datetime) == 2017, month(datetime) == 9, day(datetime) == 30)
shasta_storage_data %>% filter(parameter_id == 15, year(datetime) == 2017, month(datetime) == 9, day(datetime) == 30) %>% pull(parameter_value)
shasta_storage_data %>% filter(parameter_id == 15, year(datetime) == 2017, month(datetime) == 9, day(datetime) == 30) %>% pull(parameter_value)/1000
runApp()
runApp()
runApp()
